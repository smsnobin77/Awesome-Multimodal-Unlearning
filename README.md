# Awesome-Multimodal-Unlearning-Survey
A survey repository on multimodal machine unlearning across vision, language, video, and audio‚Äîcovering methods, datasets, benchmarks, and open challenges.


## üßæ Citation

If our work supports your research or applications, we would appreciate a ‚≠ê and a citation using the BibTeX below.

```bibtex
@article{sarwar2026multimodalunlearning,
  title = {{Multimodal Unlearning Across Vision, Language, Video, and Audio: Survey of Methods, Datasets, and Benchmarks}},
  author = {Sarwar, Nobin and Roy Dipta, Shubhashis and Liu, Zheyuan and Patil, Vaidehi},
  year = {2026},
  doi = {10.36227/techrxiv.176945748.88280394/v1},
  url = {https://doi.org/10.36227/techrxiv.176945748.88280394/v1},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  month = jan
}
```

## ‚úâÔ∏è Contact

This repository is actively maintained and continuously updated üöÄ. If you notice any issues or would like your work on Multimodal Unlearning included, please open an issue or contact us via email.

**Corresponding author:** Nobin Sarwar (smsarwar96@gmail.com)
